{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projet maison n° 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "from os import walk\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. US baby names\n",
    "\n",
    "On va s'intéresser au dataset **National data** de la SSA : https://www.ssa.gov/oact/babynames/limits.html\n",
    "\n",
    "1. Télécharger le dataset des prénoms US : https://www.ssa.gov/oact/babynames/names.zip\n",
    "\n",
    "Lire la documentation associée.\n",
    "\n",
    "2. Implémenter une fonction Python qui produit un unique DataFrame avec tous les fichiers en utilisant pandas (par ex. fonction \"concat\" ou méthode \"append\"), pas de bash :)\n",
    "\n",
    "Ordre et noms des colonnes : 'year', 'name', 'gender', 'births'\n",
    "\n",
    "Le DataFrame doit être trié selon l'année croissante puis selon l'ordre défini par les différents fichiers (voir la documentation du dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# names us\n",
    "def df_names_us():\n",
    "    df_path = \"./names/\"\n",
    "    df_list = []\n",
    "    (_, _, filenames) = next(walk(df_path))\n",
    "    m = re.compile(r\"[0-9]+\")\n",
    "    for file in filenames:\n",
    "        if file.endswith(\".txt\"):\n",
    "            tmp_df = pd.read_csv(df_path + file, header=None, names=['name','gender', 'births'])\n",
    "            y = m.search(file)\n",
    "            if y:\n",
    "                tmp_df[\"year\"] = int(y.group(0))\n",
    "            else:\n",
    "                tmp_df[\"year\"] = 0\n",
    "            tmp_df = tmp_df.reindex(columns=['year','name', 'gender', 'births'])\n",
    "            df_list.append(tmp_df)\n",
    "    df = pd.concat(df_list, axis=0)\n",
    "    # Each file is sorted first on sex and then on number of occurrences in descending order.\n",
    "    # When there is a tie on the number of occurrences, names are listed in alphabetical order.\n",
    "    df = df.sort_values(by=[\"year\", \"gender\", \"births\", \"name\"], ascending=[True, True, False, True])\n",
    "    df = df.reset_index(drop=True)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Prénoms français"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On va s'intéresser au dataset **Fichiers France hors Mayotte** de l'INSEE :  https://www.insee.fr/fr/statistiques/2540004/\n",
    "\n",
    "L'idée est de charger les données et ensuite de les conformer au DataFrame des prénoms US. Ainsi, toute manipulation sur le DataFrame des prénoms US pourra être directement réutilisée avec le DataFrame des prénoms français.\n",
    " \n",
    "1. Télécharger le dataset des prénoms français : https://www.insee.fr/fr/statistiques/fichier/2540004/nat2020_csv.zip\n",
    "\n",
    "\n",
    "Lire la documentation, ça peut être utile...\n",
    " \n",
    "2. Implémenter une fonction Python qui produit un DataFrame avec les prénoms français en prenant le DataFrame des prénoms US comme modèle :\n",
    " \n",
    " - Même ordre et mêmes noms des colonnes : year, name, gender, births\n",
    " - Mêmes dtypes pour les colonnes\n",
    " - Mêmes valeurs pour la colonne 'gender'\n",
    " - Seuls les prénoms de 2 caractères et plus sont conservés\n",
    " - La casse des prénoms doit être identique : initiales en majuscule, autres lettres en minuscule\n",
    " - Les lignes avec des données inutilisables doivent être supprimées\n",
    " - Les données sont triées à l'identique : années (↑), puis gender (↑), puis births (↓) et enfin name (↑)\n",
    " - L'index du DataFrame doit aller de 0 à N-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# names fr\n",
    "def df_names_fr():\n",
    "    df = pd.read_csv(\"nat2020.csv\", header=0, sep=\";\", names=['gender', 'name', 'year', 'births'], keep_default_na=False,\n",
    "                     dtype={\"gender\":'int', \"name\":'string', \"year\":\"string\", \"births\":\"int\"})    \n",
    "    # Modalité : 1 pour masculin, 2 pour féminin \n",
    "    df[\"gender\"] = df[\"gender\"].map({1: \"M\", 2: \"F\"})\n",
    "    # même ordre pour les colonnes\n",
    "    df = df.reindex(columns=['year', 'name', 'gender', 'births'])\n",
    "    # prénoms 2 chars ou +\n",
    "    df = df.loc[df[\"name\"].str.len() >= 2]\n",
    "    # Première lettre en majuscule et le reste en minuscule\n",
    "    df[\"name\"] = df[\"name\"].str.capitalize()\n",
    "    # on drop les lignes avec valeur \"_prenoms_rares\" à la place du nom\n",
    "    df = df.loc[df[\"name\"] != \"_prenoms_rares\"]\n",
    "    # on drop les années non définies\n",
    "    df = df.loc[df[\"year\"] != \"XXXX\"]\n",
    "    # on convertit les années en nombre entier\n",
    "    df[\"year\"] = df[\"year\"].astype(int)\n",
    "    # triage identique aux prénoms US\n",
    "    df = df.sort_values(by=[\"year\", \"gender\", \"births\", \"name\"], ascending=[True, True, False, True])\n",
    "    # reset index\n",
    "    df = df.reset_index(drop=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Taux de change"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On va s'intéresser au dataset des cours des devises de la Banque de France :  http://webstat.banque-france.fr/fr/#/downloading\n",
    "\n",
    "L'idée est de charger les données, de les nettoyer et de pouvoir accéder aux cours de certaines devises à partir de leur code ISO3.\n",
    " \n",
    "1. Utiliser le dataset des taux de change fourni.\n",
    "\n",
    "\n",
    "2. Implémenter une fonction qui produit un DataFrame avec les taux de change par date pour une liste de codes ISO3 de devises passée en argument. L'index du DataFrame doit correspondre aux dates (voir la fonction pd.to_datetime() avec le format '%d/%m/%Y'). Les colonnes du DataFrame doivent correspondre aux devises."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# taux de change\n",
    "def df_taux_change(devises):\n",
    "    filename = \"Webstat_Export_20210929.csv\"\n",
    "    # load le dataset\n",
    "    df = pd.read_csv(filename, sep=\";\", header=None)\n",
    "    # transpose pour avoir le Titre en colonne\n",
    "    df_t = df.T\n",
    "    # on extrait le code iso3 de la colonne Titre\n",
    "    df_t[[\"iso3\"]] = df_t[0].str.extract(\"\\((\\w+)\\)\").astype(str)\n",
    "    df_t[\"iso3\"][0] = \"date\"\n",
    "\n",
    "    # on remet le dataset dans le sens initial\n",
    "    df = df_t.T.reset_index(drop=True)\n",
    "    # les codes iso deviennent les noms de colonnes\n",
    "    df.columns = df.iloc[-1,:]\n",
    "    df.columns.name = None\n",
    "    # on drop les 5 premières lignes du dataset ainsi que la dernière\n",
    "    df = df.drop(df.index[:6]).drop(df.index[-1])\n",
    "    # on parse les dates en datetime\n",
    "    df[\"date\"] = pd.to_datetime(df[\"date\"], dayfirst=True)\n",
    "    # on remplace les , par . et le - par NaN pour pouvoir transformer les taux de change en float\n",
    "    df.iloc[:, 1:] = df.iloc[:, 1:].replace({r\",\": \".\", r\"\\-\": np.nan}, regex=True).astype(float)\n",
    "    # on utilise les dates comme index\n",
    "    df = df.set_index(\"date\")\n",
    "    # on commence par fill les NaN avec la methode bfill (des dates les + anciennes vers les + récentes)\n",
    "    # s'il reste des NaN on fill en forward fill (du + récent au + ancien)\n",
    "    df = df.fillna(method='bfill', axis=0).fillna(method='ffill', axis=0)\n",
    "    \n",
    "    return df.loc[:, devises]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest\n",
    "\n",
    "class Lesson4Tests(unittest.TestCase):\n",
    "    def test_df_names_us(self):\n",
    "        df = df_names_us()\n",
    "        # colonnes\n",
    "        self.assertEqual(list(df.columns), ['year', 'name', 'gender', 'births'])\n",
    "        # lignes\n",
    "        self.assertEqual(len(df), 2020863)\n",
    "        # index\n",
    "        self.assertTrue(isinstance(df.index, pd.core.indexes.range.RangeIndex))\n",
    "        # test NaN\n",
    "        self.assertTrue(df.loc[df.isnull().any(axis=1)].empty)\n",
    "        \n",
    "    def test_df_names_fr(self):\n",
    "        df = df_names_fr()\n",
    "        # colonnes\n",
    "        self.assertEqual(list(df.columns), ['year', 'name', 'gender', 'births'])\n",
    "        # lignes\n",
    "        self.assertEqual(len(df), 630407)\n",
    "        # index\n",
    "        self.assertTrue(isinstance(df.index, pd.core.indexes.range.RangeIndex))\n",
    "        # test names\n",
    "        self.assertTrue(df.loc[df['name'].str.contains('^[A-Z]+(?:-[A-Z]+)?$')].empty)\n",
    "        # test gender\n",
    "        self.assertEqual(len(df), len(df.loc[df['gender']=='F']) + len(df.loc[df['gender']=='M']))\n",
    "        # test NaN\n",
    "        self.assertTrue(df.loc[df.isnull().any(axis=1)].empty)\n",
    "\n",
    "    def test_df_taux_change(self):\n",
    "        df = df_taux_change(['CHF', 'GBP', 'USD'])\n",
    "        # colonnes\n",
    "        self.assertEqual(list(df.columns), ['CHF', 'GBP', 'USD'])\n",
    "        # index\n",
    "        self.assertTrue(isinstance(df.index, pd.core.indexes.datetimes.DatetimeIndex))\n",
    "        # types taux\n",
    "        self.assertTrue((df.dtypes == 'float').all())\n",
    "        # test NaN\n",
    "        self.assertTrue(df.loc[df.isnull().any(axis=1)].empty)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run tests\n",
    "def run_tests():\n",
    "    test_suite = unittest.makeSuite(Lesson4Tests)\n",
    "    runner = unittest.TextTestRunner(verbosity=2)\n",
    "    runner.run(test_suite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_df_names_fr (__main__.Lesson4Tests) ... ok\n",
      "test_df_names_us (__main__.Lesson4Tests) ... ok\n",
      "test_df_taux_change (__main__.Lesson4Tests) ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 3 tests in 9.362s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "# run tests\n",
    "run_tests()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
